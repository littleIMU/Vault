---
priority: 3rd
status: dormant
url: 
category: 
parent: 
children: 
link_action: 
link_topic: 
link_project: 
link_course: 
link_notes: 
---
Up Level: (parent:: [Particle Filter](Particle%20Filter.md))

In [statistics](https://en.wikipedia.org/wiki/Statistics), **Markov chain Monte Carlo** (**MCMC**) methods comprise a class of [algorithms](https://en.wikipedia.org/wiki/Algorithm) for sampling from a [probability distribution](https://en.wikipedia.org/wiki/Probability_distribution). By constructing a [Markov chain](https://en.wikipedia.org/wiki/Markov_chain) that has the desired distribution as its [equilibrium distribution](https://en.wikipedia.org/wiki/Markov_chain#Steady-state_analysis_and_limiting_distributions), one can obtain a sample of the desired distribution by recording states from the chain. The more steps that are included, the more closely the distribution of the sample matches the actual desired distribution. Various algorithms exist for constructing chains, including the [Metropolis–Hastings algorithm](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm)
.